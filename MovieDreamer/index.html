<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MovieDreamer</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <link rel="stylesheet" href="styles.css">
    <link href="../css/cs.css" rel="stylesheet">

    <!-- <script type="text/javascript" src="scroll.js"></script> -->

     <style>
      body {
        background: #fdfcf9 no-repeat fixed top left;
        font-family:'DM Mono','Open Sans', sans-serif;
      }
    </style>


</head>
<body>
    <header>
        <div class="container">
            <h1>MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequences</h1>
            <div class="details">Canyu Zhao <sup>* 1</sup>, Mingyu Liu <sup>* 1</sup>, Wen Wang <sup>1</sup>, Jianlong Yuan <sup>2</sup>, Hao Chen <sup>1</sup>, Bo Zhang <sup>1</sup>, Chunhua Shen <sup>1</sup></div>
            <div class="details"><sup>1</sup>Zhejiang University, <sup>2</sup>Alibaba Group</div>
            <div class="details"><sup>*</sup>Equal Contribution</div>
            <div class="links">
                <a href="https://github.com/aim-uofa/MovieDreamer" target="_blank">
                    <i class="fab fa-github"></i> GitHub
                </a>
                <a href="https://arxiv.org/abs/2407.16655" target="_blank">
                    <i class="fas fa-file-alt"></i> arXiv
                </a>
            </div>
        </div>
    </header>
    <div class="container main">
        <section class="section section-abstract">
            <div class="add-div" style="height: 150px;">
                <image src="images/logo.png" height="150"/>
            </div>
            <h2>Abstract</h2>
            <div class="abs">Recent advancements in video generation have primarily leveraged diffusion models for short-duration content. However, these approaches often fall short in modeling complex narratives and maintaining character consistency over extended periods, which is essential for long-form video production like movies. We propose MovieDreamer, a novel hierarchical framework that integrates the strengths of autoregressive models with diffusion-based rendering to pioneer long-duration video generation with intricate plot progressions and high visual fidelity. Our approach utilizes autoregressive models for global narrative coherence, predicting sequences of visual tokens that are subsequently transformed into high-quality video frames through diffusion rendering. This method is akin to traditional movie production processes, where complex stories are factorized down into manageable scene capturing. Further, we employ a multimodal script
that enriches scene descriptions with detailed character information and visual style, enhancing continuity and character identity across scenes. We present extensive experiments across various movie genres, demonstrating that our approach not only achieves superior visual and narrative quality but also effectively extends the duration of generated content significantly beyond current capabilities. 
            </div>
        </section>

        <section class="section section-other">
            <h2>Demo</h2>
            <div class="titanic-title">
                <image src="images/TITANIC.png" width="150"/>
            </div>

            <div class="add-div" style="height: 515px;">
                <image src="images/demo.png" height="515"/>
            </div>

            <div class="video">
                <iframe src="https://www.youtube.com/embed/aubRVOGrKLU" frameborder="0" allowfullscreen></iframe>
            </div>

            <div class="video">
                <iframe src="https://player.bilibili.com/player.html?isOutside=true&aid=112817667574324&bvid=BV1o48MeHEoH&cid=500001621338716&p=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"></iframe>
            </div>

        </section>

        <section class="section section-other">
            <h2>Story Results</h2>
            <div class="abs">Our MovieDreamer is able to generate very long story results with multiple characters well preserved.</div>
            <div class="carousel">
                <div class="carousel-inner">
                    <img src="images/add_story0.png">
                    <img src="images/add_story1.png">
                    <img src="images/add_story2.png">
                    <img src="images/add_story3.png">
                    <img src="images/add_story4.png">
                    <img src="images/add_story5.png">
                    <img src="images/add_story6.png">
                </div>
                <div class="carousel-buttons">
                    <button id="prev">❮</button>
                    <button id="next">❯</button>
                </div>
            </div>

        </section>
        <section class="section section-other">
            <h2>Video Results</h2>
            <div class="abs">MovieDreamer is <b>ORTHOGONAL</b> to existing long video generation methods, but benefits from them. </div>
            <div class="abs">
                Existing long video generation methods typically focus on generating a long video clip with one image or text as input, ensuring high-quality results of tens of seconds. However, it is extremely computational intensive to scale them up to generate a long video of minutes, and almost impossible for hours. We address this problem from a different perspective, namely, by generating long videos in a hierarchical way. Specifically, we first generate keyframes, which serve as anchor frames to generate the long video. Moreover, our paradigm unifies long story generation and long video generation. Firstly, we surpass the existing methods in terms of the length of the generated content, both in story and video generation, while ensuring no degradation in quality. Secondly, our generation quality also exceeds the current state-of-the-art methods, which is demonstrated in the evaluation metrics. Lastly, our method is highly flexible, allowing the use of some of the current high-quality closed-source video generation models to create exceptionally high-quality long videos with rich narrative, with multiple-character consistency well-preserved.
            </div>

            <h3>MovieDreamer + Luma</h3>
            <div class="video-grid">
                <video controls>
                    <source src="videos/luma/long1.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <video controls>
                    <source src="videos/luma/long2.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <video controls>
                    <source src="videos/luma/long3.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>

            <h3>MovieDreamer + Our Video Model</h3>
            <div class="abs">
                As a university lab, it is not feasible for us to achieve as good performance as companies in resource-intensive video generation model training. Nevertheless, we still introduce an improved model based on existing methods to generate longer video clips.
            </div>
            <div class="video-grid">
                <video controls>
                    <source src="videos/ours/long1.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <video controls>
                    <source src="videos/ours/long2.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <video controls>
                    <source src="videos/ours/long3.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
            </div>

        </section>
        <section class="section section-other">
            <h2>Character ID Preservation</h2>
            <div class="abs">MovieDreamer is able to preserve character identity over long time spans in a zero-shot manner.</div>
            <div class="add-div" style="height: 730px;">
                <image src="images/ID.png" height="730"/>
            </div>
        </section>
        <section class="section section-other">
            <h2>Methodology</h2>
            <div class="abs">
                Inspired by movie industry, we design the multimodal script which helps the model to better understand the character, the scene, and the plot.
            </div>
            <div class="abs">
                Our autoregressive model takes multimodal scripts as input and predicts the tokens for keyframes. These tokens are then rendered into images, forming anchor frames for extended video generation. For more details, please refer to our paper.
            </div>
            <div class="add-div" style="height: 440px;">
                <image src="images/Method.png" height="440"/>
            </div>
        </section>
        <section class="section section-other">
            <h2>Compared with Existing Methods</h2>
            <div class="abs">
                Firstly, our generation paradigm can produce rich, narrative content, significantly surpassing existing methods in terms of duration. The long content we generate is not simply looping. Secondly, quantitative metrics robustly demonstrate that our method ensures high-quality results while generating lengthy content.
            </div>

            <div class="add-div" style="height: 245px;">
                <image src="images/story_metrics.png" height="245"/>
            </div>
            <div class="add-div" style="height: 200px; text-align: center ">
                <image src="images/video_metrics.png" height="200"/>
            </div>
        </section>

        <section class="section section-other">
            <h2>Bibtex</h2>
            <div>
                <pre>
                
@misc{zhao2024moviedreamer, 
    title={MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequence}, 
    author={Canyu Zhao and Mingyu Liu and Wen Wang and Jianlong Yuan and Hao Chen and Bo Zhang and Chunhua Shen},
    year={2024},
    url={https://arxiv.org/abs/2407.16655}, 
}
                    
                </pre>
            </div>
        </section>
    </div>
    <script>
        const carouselInner = document.querySelector('.carousel-inner');
        const images = document.querySelectorAll('.carousel img');
        let currentIndex = 0;
        let autoPlayInterval;
    
        function showImage(index) {
            const offset = -index * 100; // Assuming each image takes 100% of the container width
            carouselInner.style.transform = `translateX(${offset}%)`;
        }
    
        function nextImage() {
            currentIndex = (currentIndex < images.length - 1) ? currentIndex + 1 : 0;
            showImage(currentIndex);
            resetAutoPlay();
        }
    
        function prevImage() {
            currentIndex = (currentIndex > 0) ? currentIndex - 1 : images.length - 1;
            showImage(currentIndex);
            resetAutoPlay();
        }
    
        function resetAutoPlay() {
            clearInterval(autoPlayInterval);
            autoPlayInterval = setInterval(nextImage, 8000);
        }
    
        document.getElementById('prev').addEventListener('click', prevImage);
        document.getElementById('next').addEventListener('click', nextImage);
    
        // Initialize auto-play
        autoPlayInterval = setInterval(nextImage, 8000);
    
        // Seamless transition between the last and first image
        carouselInner.addEventListener('transitionend', () => {
            if (currentIndex === images.length) {
                carouselInner.style.transition = 'none';
                currentIndex = 0;
                showImage(currentIndex);
                requestAnimationFrame(() => {
                    carouselInner.style.transition = 'transform 1s ease';
                });
            }
            if (currentIndex === -1) {
                carouselInner.style.transition = 'none';
                currentIndex = images.length - 1;
                showImage(currentIndex);
                requestAnimationFrame(() => {
                    carouselInner.style.transition = 'transform 1s ease';
                });
            }
        });
    </script>
</body>
</html>
